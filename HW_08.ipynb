{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import HalvingRandomSearchCV as HRSCV\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from project_module import regression_report\n",
    "from project_module.feature_selection import SelectKBestByCoefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1095, 89) (1095,) (365, 89) (365,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Your code here: 讀取資料 \"\"\"\n",
    "# load data\n",
    "x_train = np.load('./x_train.npy')\n",
    "y_train = np.load('./y_train.npy')\n",
    "x_test = np.load('./x_test.npy')\n",
    "y_test = np.load('./y_test.npy')\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解題步驟：\n",
    "\n",
    "1. 讀取 x_train.npy, y_train.npy, x_test.npy, y_test.npy\n",
    "2. 先以上課的知識或 default hyperparameter 調整出一個不會 over-fitting 太多的 XGBoost 模型\n",
    "3. 以該組超參數為基準，搜尋附近的參數(可以用自己偏好的搜尋策略)\n",
    "4. 將最終調整結果與一開始的模型做比較，誤差是否有降低\n",
    "5. 請比較 Random Forest, XGBoost(有時間的同學可以增加 GBDT, Adaboost) 的超參數搜尋時間與誤差(記得要控制 n_estimators 等會影響到時間的參數，使其叫)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Your code here: 初始化一個 XGBoost 模型並判斷其誤差 \"\"\"\n",
    "\n",
    "def get_XGBoost(params: dict) -> XGBRegressor:\n",
    "    XGB = XGBRegressor(**params)\n",
    "    return XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 1577792384.2319\n",
      "mae = 18800.7493\n",
      "rmse = 39721.4348\n",
      "mape = 0.1029\n"
     ]
    }
   ],
   "source": [
    "XGB = XGBRegressor()\n",
    "XGB.fit(x_train, y_train)\n",
    "\n",
    "pred = XGB.predict(x_test)\n",
    "regression_report(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [XGBoost 官方文檔](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)\n",
    "\n",
    "## 計算 XGBoost 超參數搜尋時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Your code here: 搜尋超參數，並計算搜尋時間 \"\"\"\n",
    "XGB = XGBRegressor(n_jobs = -1)\n",
    "\n",
    "# set searching hyperparameters\n",
    "search_params = {\n",
    "    'n_estimators': np.arange(70, 200),\n",
    "    'max_depth': np.arange(4, 8),\n",
    "    'eta': np.abs(norm(loc = 0.3, scale = 0.5).rvs(size=40)),\n",
    "    'objective': ['reg:squarederror', 'reg:squaredlogerror', 'reg:pseudohubererror'],\n",
    "    'min_child_weight': np.abs(norm(loc = 1, scale = 0.5).rvs(size=40)),\n",
    "    'subsample': np.arange(0.7, 1, 0.01),\n",
    "    'lambda': np.arange(0.01, 1, 0.05),\n",
    "    'alpha': np.arange(0.01, 1, 0.05)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Successive Halving algorithm\n",
    "SH_search = HRSCV(\n",
    "    estimator = XGB, param_distributions = search_params, n_candidates = 200, \n",
    "    factor = 2, resource = 'n_samples', max_resources='auto', min_resources='smallest', \n",
    "    aggressive_elimination=False, cv=3, scoring='neg_mean_absolute_percentage_error', refit=True,\n",
    "    return_train_score=True, random_state=None, n_jobs=-1, verbose=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f8de40b4340b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSH_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_samples_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# Set best_score_: BaseSearchCV does not set it, as refit is a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search_successive_halving.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    317\u001b[0m                             'n_resources': [n_resources] * n_candidates}\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             results = evaluate_candidates(candidate_params, cv,\n\u001b[0m\u001b[0;32m    320\u001b[0m                                           more_results=more_results)\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    785\u001b[0m                                     more_results=None):\n\u001b[0;32m    786\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                 \u001b[0mcandidate_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m                 \u001b[0mn_candidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    289\u001b[0m                     % (grid_size, self.n_iter, grid_size), UserWarning)\n\u001b[0;32m    290\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m             for i in sample_without_replacement(grid_size, n_iter,\n\u001b[0m\u001b[0;32m    292\u001b[0m                                                 random_state=rng):\n\u001b[0;32m    293\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\utils\\_random.pyx\u001b[0m in \u001b[0;36msklearn.utils._random.sample_without_replacement\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "SH_search.fit(x_train, y_train)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRSCV ended in -582.1792s\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HalvingRandomSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-60aded359ecf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'HRSCV ended in {end - start:.4f}s\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Best score is {(-1) * SH_search.best_score_:.4f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Best params is {SH_search.best_params_}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HalvingRandomSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "print(f'HRSCV ended in {end - start:.4f}s\\n')\n",
    "\n",
    "print(f'Best score is {(-1) * SH_search.best_score_:.4f}')\n",
    "print(f'Best params is {SH_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 XGBoost 單輪訓練時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost was trained in 0.3172s\n",
      "\n",
      "mse = 1010869446.2126\n",
      "mae = 15842.4891\n",
      "rmse = 31794.1731\n",
      "mape = 0.0904\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Your code here: 使用搜尋到的參數分析在 testing data 上的誤差表現，並計算時間 \"\"\"\n",
    "# 這組參數是我搜尋到比較好的一組參數\n",
    "best_params = {'subsample': 0.71, 'objective': 'reg:squarederror', 'n_estimators': 135, 'min_child_weight': 1.106778500318303, 'max_depth': 4, 'lambda': 0.66, 'eta': 0.06554882531678949, 'alpha': 0.81}\n",
    "best_params['n_jobs'] = -1\n",
    "XGB = get_XGBoost(best_params)\n",
    "\n",
    "start = time.time()\n",
    "XGB.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(f'XGBoost was trained in {end - start:.4f}s\\n')\n",
    "\n",
    "pred = XGB.predict(x_test)\n",
    "regression_report(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 Random Forest 超參數搜尋時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRSCV ended in 136.2125s\n",
      "\n",
      "Best score is 0.1087\n",
      "Best params is {'n_estimators': 151, 'min_samples_split': 2, 'min_impurity_decrease': 1.217730660943888, 'max_samples': 0.9700000000000002, 'max_features': 'sqrt', 'max_depth': 13, 'criterion': 'mse', 'ccp_alpha': 0.7034844342131232}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Your code here: 搜尋 Random Forest 超參數，並計算搜尋時間 \"\"\"\n",
    "RF = RandomForestRegressor(n_jobs = -1)\n",
    "\n",
    "# set searching hyperparameters\n",
    "search_params = {\n",
    "    'n_estimators': np.arange(70, 200),\n",
    "    'max_depth': np.arange(7, 20),\n",
    "    'ccp_alpha': np.abs(norm(loc = 1.5, scale = 0.5).rvs(size=20)),\n",
    "    'criterion': ['mae', 'mse'],\n",
    "    'min_samples_split': np.arange(2, 10),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_impurity_decrease': np.abs(norm(loc = 1, scale = 0.5).rvs(size=40)),\n",
    "    'max_samples': np.arange(0.7, 0.99, 0.01)\n",
    "}\n",
    "\n",
    "# set Successive Halving algorithm\n",
    "SH_search = HRSCV(\n",
    "    estimator = RF, param_distributions = search_params, n_candidates = 200, \n",
    "    factor = 2, resource = 'n_samples', max_resources='auto', min_resources='smallest', \n",
    "    aggressive_elimination=False, cv=3, scoring='neg_mean_absolute_percentage_error', refit=True,\n",
    "    return_train_score=True, random_state=None, n_jobs = -1, verbose=0\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "SH_search.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(f'HRSCV ended in {end - start:.4f}s\\n')\n",
    "\n",
    "print(f'Best score is {(-1) * SH_search.best_score_:.4f}')\n",
    "print(f'Best params is {SH_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 Random Forest 單輪訓練時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest was trained in 0.2551s\n",
      "\n",
      "mse = 1261008143.8174\n",
      "mae = 18715.7155\n",
      "rmse = 35510.6765\n",
      "mape = 0.1061\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Your code here: 使用搜尋到的參數分析在 testing data 上的誤差表現，並計算時間 \"\"\"\n",
    "best_params = {'n_estimators': 107, 'min_samples_split': 3, 'min_impurity_decrease': 1.5204750662278061, 'max_samples': 0.81, 'max_features': 'sqrt', 'max_depth': 11, 'criterion': 'mse', 'ccp_alpha': 1.205496871022525}\n",
    "best_params['n_jobs'] = 4\n",
    "\n",
    "RF = RandomForestRegressor(**best_params)\n",
    "start = time.time()\n",
    "RF.fit(x_train, y_train)\n",
    "end = time.time()\n",
    "print(f'Random Forest was trained in {end - start:.4f}s\\n')\n",
    "\n",
    "pred = RF.predict(x_test)\n",
    "regression_report(y_test, pred, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
